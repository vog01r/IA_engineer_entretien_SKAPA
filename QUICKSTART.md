# üöÄ Guide de d√©marrage rapide - SKAPA

**Pour tester les am√©liorations de performance et MCP**

---

## ‚ö†Ô∏è Pr√©requis

1. **Venv activ√©** : `source .venv/bin/activate`
2. **Variables d'environnement** : Fichier `.env` configur√©
3. **Python 3** : Utiliser `python3` (pas `python` sur macOS)

---

## üß™ Tests sans backend (tests unitaires)

### Test 1 : Conformit√© MCP

```bash
# Activer venv
source .venv/bin/activate

# Lancer test MCP (pas besoin de backend)
python3 scripts/test_mcp_compliance.py
```

**R√©sultat attendu :**
```
‚úÖ TOUS LES TESTS PASS√âS
üìä R√âSUM√â:
  ‚úÖ JSON-RPC 2.0 format
  ‚úÖ Capabilities declaration
  ‚úÖ Tools list/call endpoints
  ‚úÖ Input schemas (Pydantic)
  ‚úÖ Error handling
  ‚úÖ Annotations (audience, priority)

üí° CONFORMIT√â MCP: 100%
```

---

## üîß Tests avec backend (tests d'int√©gration)

### √âtape 1 : Lancer le backend

**Terminal 1 :**
```bash
# Activer venv
source .venv/bin/activate

# Lancer backend FastAPI
python3 -m uvicorn backend.main:app --reload --port 8000
```

**V√©rifier que √ßa tourne :**
```bash
curl http://localhost:8000/
# Doit retourner : {"message": "SKAPA Backend API", ...}
```

---

### √âtape 2 : Tester les performances

**Terminal 2 :**
```bash
# Activer venv
source .venv/bin/activate

# Lancer test performance
python3 scripts/test_bot_performance.py
```

**R√©sultat attendu :**
```
üî¨ TEST PERFORMANCE BOT TELEGRAM
================================================================================

üìç Test 1: G√©ocodage (Open-Meteo)
  Paris           ‚Üí 0.234s | Paris, France
  Tokyo           ‚Üí 0.312s | Tokyo, Japan
  New York        ‚Üí 0.289s | New York, United States

üå§Ô∏è  Test 2: API M√©t√©o (FastAPI ‚Üí Open-Meteo)
  Paris           ‚Üí 1.123s | 8¬∞C
  Tokyo           ‚Üí 1.234s | 15¬∞C
  New York        ‚Üí 1.189s | 5¬∞C

ü§ñ Test 3: Agent LLM (question m√©t√©o)
  M√©t√©o √† Paris                  ‚Üí 3.456s
    Answer: Actuellement √† Paris : 8¬∞C, ciel d√©gag√©...
  
üìä ANALYSE:
  - G√©ocodage: ~0.2-0.5s (acceptable)
  - M√©t√©o API: ~0.5-1.5s (acceptable)
  - Agent LLM: ~1-5s (BOTTLENECK PRINCIPAL)

üí° RECOMMANDATIONS:
  1. Cache m√©t√©o (10min) ‚Üí √©vite appels inutiles
  2. Cache geocoding (24h) ‚Üí √©vite r√©solutions r√©p√©t√©es
  3. Streaming LLM ‚Üí am√©liore perception UX
```

---

### √âtape 3 : V√©rifier le cache

**Apr√®s avoir lanc√© quelques requ√™tes :**

```bash
# V√©rifier stats cache
curl http://localhost:8000/cache/stats

# R√©sultat attendu :
{
  "cache": {
    "hits": 15,
    "misses": 5,
    "total": 20,
    "hit_rate": 75.0,
    "size": 8
  },
  "interpretation": {
    "hit_rate": "75.0%",
    "efficiency": "excellent"
  }
}
```

**Interpr√©tation :**
- **hit_rate > 70%** : Excellent (cache tr√®s efficace)
- **hit_rate 50-70%** : Bon (cache utile)
- **hit_rate < 50%** : Faible (requ√™tes trop vari√©es)

---

## ü§ñ Tester le bot Telegram

### √âtape 1 : V√©rifier le token

```bash
# V√©rifier que TELEGRAM_BOT_TOKEN est d√©fini
grep TELEGRAM_BOT_TOKEN .env
```

### √âtape 2 : Lancer le bot

**Terminal 3 :**
```bash
# Activer venv
source .venv/bin/activate

# Lancer bot (avec logs timing)
python3 -m backend.services.bot.telegram_bot
```

**Logs attendus :**
```
INFO - ü§ñ Bot Telegram d√©marr√© (polling mode)
INFO - ‚è±Ô∏è [GEOCODING] 'Paris' took 0.234s
INFO - ‚è±Ô∏è [WEATHER_FETCH] took 0.567s
INFO - ‚è±Ô∏è [WEATHER_LOCATION] took 0.123s
INFO - ‚è±Ô∏è [WEATHER_TOTAL] took 0.690s
INFO - ‚è±Ô∏è [AGENT_LLM] question='M√©t√©o √† Paris'... took 3.456s
INFO - ‚è±Ô∏è [TOTAL_RESPONSE] user_message='M√©t√©o √† Paris'... took 4.146s
```

### √âtape 3 : Tester dans Telegram

1. Ouvrir Telegram
2. Chercher ton bot (nom dans `.env`)
3. Envoyer : `/start`
4. Envoyer : `M√©t√©o √† Paris`
5. **Observer les logs** dans le terminal pour voir les timings

**Avec cache (2√®me requ√™te identique) :**
```
INFO - ‚è±Ô∏è [GEOCODING] 'Paris' took 0.001s  ‚Üê Cache HIT !
INFO - ‚è±Ô∏è [WEATHER_TOTAL] took 0.002s     ‚Üê Cache HIT !
INFO - ‚è±Ô∏è [AGENT_LLM] question='M√©t√©o √† Paris'... took 2.123s
INFO - ‚è±Ô∏è [TOTAL_RESPONSE] took 2.126s    ‚Üê Gain -50% !
```

---

## üîå Tester le MCP Server

### Mode 1 : stdio (Claude Desktop)

**Configuration Claude Desktop** (`~/Library/Application Support/Claude/claude_desktop_config.json`) :

```json
{
  "mcpServers": {
    "skapa": {
      "command": "python3",
      "args": [
        "-m",
        "backend.services.mcp.server"
      ],
      "cwd": "/Users/chabanis/Documents/code dev/SKAPA/IA_engineer_entretien_SKAPA",
      "env": {
        "PYTHONPATH": "/Users/chabanis/Documents/code dev/SKAPA/IA_engineer_entretien_SKAPA"
      }
    }
  }
}
```

**Tester :**
1. Red√©marrer Claude Desktop
2. Ouvrir une conversation
3. Les tools SKAPA devraient appara√Ætre
4. Tester : "Quelle est la m√©t√©o √† Paris ?" (utilise `get_weather`)

### Mode 2 : HTTP (local)

**Terminal 4 :**
```bash
# Activer venv
source .venv/bin/activate

# Lancer MCP en HTTP
python3 backend/services/mcp/run_http.py
```

**Tester :**
```bash
# Lister les tools
curl -X POST http://localhost:8001/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "id": 1,
    "method": "tools/list"
  }'

# Appeler get_weather
curl -X POST http://localhost:8001/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "id": 2,
    "method": "tools/call",
    "params": {
      "name": "get_weather",
      "arguments": {
        "latitude": 48.8566,
        "longitude": 2.3522
      }
    }
  }'
```

---

## üêõ Troubleshooting

### Erreur : "command not found: python"

**Solution :** Utiliser `python3` au lieu de `python` sur macOS.

```bash
# V√©rifier version Python
python3 --version  # Doit afficher Python 3.x
```

### Erreur : "ModuleNotFoundError: No module named 'requests'"

**Solution :** Activer le venv.

```bash
source .venv/bin/activate
# Le prompt doit afficher (.venv)
```

### Erreur : "Connection refused" (test_bot_performance.py)

**Solution :** Lancer le backend d'abord.

```bash
# Terminal 1
python3 -m uvicorn backend.main:app --reload --port 8000

# Terminal 2 (apr√®s que le backend soit lanc√©)
python3 scripts/test_bot_performance.py
```

### Backend ne d√©marre pas : "ModuleNotFoundError: No module named 'backend'"

**Solution :** Lancer depuis la racine du projet.

```bash
cd "/Users/chabanis/Documents/code dev/SKAPA/IA_engineer_entretien_SKAPA"
python3 -m uvicorn backend.main:app --reload --port 8000
```

---

## üìä Checklist validation am√©liorations

### ‚úÖ Performance

- [ ] Backend lanc√© (`curl http://localhost:8000/`)
- [ ] Test performance ex√©cut√© (`python3 scripts/test_bot_performance.py`)
- [ ] Logs timing visibles (‚è±Ô∏è [OPERATION] took X.XXs)
- [ ] Cache stats v√©rifi√©es (`curl http://localhost:8000/cache/stats`)
- [ ] Hit rate > 50% apr√®s plusieurs requ√™tes

### ‚úÖ MCP

- [ ] Test conformit√© pass√© (`python3 scripts/test_mcp_compliance.py`)
- [ ] MCP HTTP lanc√© (`python3 backend/services/mcp/run_http.py`)
- [ ] Tools list√©s (`curl -X POST http://localhost:8001/mcp ...`)
- [ ] Claude Desktop configur√© (optionnel)

### ‚úÖ Bot Telegram

- [ ] Bot lanc√© (`python3 -m backend.services.bot.telegram_bot`)
- [ ] Logs timing visibles
- [ ] Requ√™te test dans Telegram
- [ ] Cache observ√© (2√®me requ√™te plus rapide)

---

## üéØ D√©monstration pour le senior

**Sc√©nario recommand√© :**

1. **Montrer les commits** : `git log --oneline --graph -5`
2. **Lancer backend** : Terminal 1
3. **Montrer cache vide** : `curl http://localhost:8000/cache/stats` ‚Üí 0 hits
4. **Lancer test performance** : Terminal 2 ‚Üí Observer timings
5. **Montrer cache rempli** : `curl http://localhost:8000/cache/stats` ‚Üí hit_rate > 60%
6. **Lancer test MCP** : `python3 scripts/test_mcp_compliance.py` ‚Üí 100% conforme
7. **Montrer documentation** : Ouvrir `docs/ARCHITECTURE.md`, `docs/PERFORMANCE_ANALYSIS.md`

**Phrase cl√© :** "J'ai mesur√© avant d'optimiser. Le bottleneck principal est le LLM (70-90% du temps). Le cache r√©duit le temps de r√©ponse de 40-50% sur les requ√™tes r√©p√©t√©es."

---

**Bon courage pour le debrief ! üöÄ**
