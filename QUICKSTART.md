# üöÄ Guide de d√©marrage rapide - SKAPA

**Pour tester les am√©liorations de performance et MCP**

---

## ‚ö†Ô∏è Pr√©requis

1. **Venv activ√©** : `source .venv/bin/activate` (les commandes ci-dessous supposent le venv activ√©)
2. **D√©pendances install√©es** : `pip install -r requirements.txt`
3. **Variables d'environnement** : Fichier `.env` configur√©
4. **Python 3** : Utiliser `python3` (pas `python` sur macOS)

### Installation initiale (une seule fois)

```bash
cd "/Users/chabanis/Documents/code dev/SKAPA/IA_engineer_entretien_SKAPA"
source .venv/bin/activate

# Installer toutes les d√©pendances
pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org -r requirements.txt

# Si erreur SSL, installer manuellement :
pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org \
  'passlib[bcrypt]' python-multipart slowapi email-validator
```

---

## üß™ Tests sans backend (tests unitaires)

### Test 1 : Conformit√© MCP (format)

```bash
source .venv/bin/activate
python3 scripts/test_mcp_compliance.py
```

**R√©sultat attendu :** `‚úÖ TOUS LES TESTS PASS√âS` et `üí° CONFORMIT√â MCP: 100%`

### Test 1b : E2E MCP (serveur HTTP r√©el)

```bash
source .venv/bin/activate
PYTHONPATH=. python3 scripts/test_mcp_e2e.py
```

**R√©sultat attendu :** `Tous les tests E2E MCP sont pass√©s.` (initialize ‚Üí tools/list ‚Üí tools/call)

---

## üîß Tests avec backend (tests d'int√©gration)

### √âtape 1 : Lancer le backend

**Terminal 1 :**
```bash
# Activer venv
source .venv/bin/activate

# Lancer backend FastAPI
python3 -m uvicorn backend.main:app --reload --port 8000
```

**V√©rifier que √ßa tourne :**
```bash
curl http://localhost:8000/
# Doit retourner : {"message": "SKAPA Backend API", ...}
```

---

### √âtape 2 : Tester les performances

**Terminal 2 :**
```bash
# Activer venv
source .venv/bin/activate

# Lancer test performance
python3 scripts/test_bot_performance.py
```

**R√©sultat attendu :**
```
üî¨ TEST PERFORMANCE BOT TELEGRAM
================================================================================

üìç Test 1: G√©ocodage (Open-Meteo)
  Paris           ‚Üí 0.234s | Paris, France
  Tokyo           ‚Üí 0.312s | Tokyo, Japan
  New York        ‚Üí 0.289s | New York, United States

üå§Ô∏è  Test 2: API M√©t√©o (FastAPI ‚Üí Open-Meteo)
  Paris           ‚Üí 1.123s | 8¬∞C
  Tokyo           ‚Üí 1.234s | 15¬∞C
  New York        ‚Üí 1.189s | 5¬∞C

ü§ñ Test 3: Agent LLM (question m√©t√©o)
  M√©t√©o √† Paris                  ‚Üí 3.456s
    Answer: Actuellement √† Paris : 8¬∞C, ciel d√©gag√©...
  
üìä ANALYSE:
  - G√©ocodage: ~0.2-0.5s (acceptable)
  - M√©t√©o API: ~0.5-1.5s (acceptable)
  - Agent LLM: ~1-5s (BOTTLENECK PRINCIPAL)

üí° RECOMMANDATIONS:
  1. Cache m√©t√©o (10min) ‚Üí √©vite appels inutiles
  2. Cache geocoding (24h) ‚Üí √©vite r√©solutions r√©p√©t√©es
  3. Streaming LLM ‚Üí am√©liore perception UX
```

---

### √âtape 3 : V√©rifier le cache

**Apr√®s avoir lanc√© quelques requ√™tes :**

```bash
# V√©rifier stats cache
curl http://localhost:8000/cache/stats

# R√©sultat attendu :
{
  "cache": {
    "hits": 15,
    "misses": 5,
    "total": 20,
    "hit_rate": 75.0,
    "size": 8
  },
  "interpretation": {
    "hit_rate": "75.0%",
    "efficiency": "excellent"
  }
}
```

**Interpr√©tation :**
- **hit_rate > 70%** : Excellent (cache tr√®s efficace)
- **hit_rate 50-70%** : Bon (cache utile)
- **hit_rate < 50%** : Faible (requ√™tes trop vari√©es)

---

## ü§ñ Tester le bot Telegram

### √âtape 1 : V√©rifier le token

```bash
# V√©rifier que TELEGRAM_BOT_TOKEN est d√©fini
grep TELEGRAM_BOT_TOKEN .env
```

### √âtape 2 : Lancer le bot

**Terminal 3 :**
```bash
# Activer venv
source .venv/bin/activate

# Lancer bot (avec logs timing)
python3 -m backend.services.bot.telegram_bot
```

**Logs attendus :**
```
INFO - ü§ñ Bot Telegram d√©marr√© (polling mode)
INFO - ‚è±Ô∏è [GEOCODING] 'Paris' took 0.234s
INFO - ‚è±Ô∏è [WEATHER_FETCH] took 0.567s
INFO - ‚è±Ô∏è [WEATHER_LOCATION] took 0.123s
INFO - ‚è±Ô∏è [WEATHER_TOTAL] took 0.690s
INFO - ‚è±Ô∏è [AGENT_LLM] question='M√©t√©o √† Paris'... took 3.456s
INFO - ‚è±Ô∏è [TOTAL_RESPONSE] user_message='M√©t√©o √† Paris'... took 4.146s
```

### √âtape 3 : Tester dans Telegram

1. Ouvrir Telegram
2. Chercher ton bot (nom dans `.env`)
3. Envoyer : `/start`
4. Envoyer : `M√©t√©o √† Paris`
5. **Observer les logs** dans le terminal pour voir les timings

**Avec cache (2√®me requ√™te identique) :**
```
INFO - ‚è±Ô∏è [GEOCODING] 'Paris' took 0.001s  ‚Üê Cache HIT !
INFO - ‚è±Ô∏è [WEATHER_TOTAL] took 0.002s     ‚Üê Cache HIT !
INFO - ‚è±Ô∏è [AGENT_LLM] question='M√©t√©o √† Paris'... took 2.123s
INFO - ‚è±Ô∏è [TOTAL_RESPONSE] took 2.126s    ‚Üê Gain -50% !
```

---

## üîå Tester le MCP Server

**Configuration compl√®te (Claude Desktop stdio, HTTP, ChatGPT) :** voir **[\`docs/MCP_SETUP.md\`](docs/MCP_SETUP.md)**.

**Tests rapides (venv activ√©) :**
```bash
# Conformit√© format
python3 scripts/test_mcp_compliance.py

# E2E HTTP (initialize ‚Üí tools/list ‚Üí tools/call)
PYTHONPATH=. python3 scripts/test_mcp_e2e.py
```

**Lancer le serveur MCP en HTTP :** `python3 backend/services/mcp/run_http.py` (port 8001). D√©tail et flux session : `docs/MCP_SETUP.md`.

---

## üêõ Troubleshooting

### Erreur : "command not found: python"

**Solution :** Utiliser `python3` au lieu de `python` sur macOS.

```bash
# V√©rifier version Python
python3 --version  # Doit afficher Python 3.x
```

### Erreur : "ModuleNotFoundError: No module named 'requests'"

**Solution :** Activer le venv.

```bash
source .venv/bin/activate
# Le prompt doit afficher (.venv)
```

### Erreur : "Connection refused" (test_bot_performance.py)

**Solution :** Lancer le backend d'abord.

```bash
# Terminal 1
python3 -m uvicorn backend.main:app --reload --port 8000

# Terminal 2 (apr√®s que le backend soit lanc√©)
python3 scripts/test_bot_performance.py
```

### Backend ne d√©marre pas : "ModuleNotFoundError: No module named 'backend'"

**Solution :** Lancer depuis la racine du projet.

```bash
cd "/Users/chabanis/Documents/code dev/SKAPA/IA_engineer_entretien_SKAPA"
python3 -m uvicorn backend.main:app --reload --port 8000
```

---

## üìä Checklist validation am√©liorations

### ‚úÖ Performance

- [ ] Backend lanc√© (`curl http://localhost:8000/`)
- [ ] Test performance ex√©cut√© (`python3 scripts/test_bot_performance.py`)
- [ ] Logs timing visibles (‚è±Ô∏è [OPERATION] took X.XXs)
- [ ] Cache stats v√©rifi√©es (`curl http://localhost:8000/cache/stats`)
- [ ] Hit rate > 50% apr√®s plusieurs requ√™tes

### ‚úÖ MCP

- [ ] Test conformit√© pass√© (`python3 scripts/test_mcp_compliance.py`)
- [ ] Test E2E pass√© (`PYTHONPATH=. python3 scripts/test_mcp_e2e.py`)
- [ ] Config Claude Desktop / HTTP : voir `docs/MCP_SETUP.md`

### ‚úÖ Bot Telegram

- [ ] Bot lanc√© (`python3 -m backend.services.bot.telegram_bot`)
- [ ] Logs timing visibles
- [ ] Requ√™te test dans Telegram
- [ ] Cache observ√© (2√®me requ√™te plus rapide)

---

## üéØ D√©monstration pour le senior

**Sc√©nario recommand√© :**

1. **Montrer les commits** : `git log --oneline --graph -5`
2. **Lancer backend** : Terminal 1
3. **Montrer cache vide** : `curl http://localhost:8000/cache/stats` ‚Üí 0 hits
4. **Lancer test performance** : Terminal 2 ‚Üí Observer timings
5. **Montrer cache rempli** : `curl http://localhost:8000/cache/stats` ‚Üí hit_rate > 60%
6. **Lancer test MCP** : `python3 scripts/test_mcp_compliance.py` puis `PYTHONPATH=. python3 scripts/test_mcp_e2e.py` ‚Äî d√©tail : `docs/MCP_SETUP.md`
7. **Montrer documentation** : Ouvrir `docs/ARCHITECTURE.md`

**Phrase cl√© :** "J'ai mesur√© avant d'optimiser. Le bottleneck principal est le LLM (70-90% du temps). Le cache r√©duit le temps de r√©ponse de 40-50% sur les requ√™tes r√©p√©t√©es."

---

**Bon courage pour le debrief ! üöÄ**
